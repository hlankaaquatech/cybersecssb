{
  "job_name" : "high_score_aggregate",
  "api_endpoints" : [ ],
  "sql" : "DROP  TABLE  IF  EXISTS `main_network_triage_output_kafka`;\nCREATE  TABLE `main_network_triage_output_kafka` (\n`id` STRING,\n  `ts` STRING,\n  `ip_src_addr_geo_lon` STRING,\n  `code` STRING,\n  `method` STRING,\n  `top_level_domain` STRING,\n  `ip_dst_addr_geo_lon` STRING,\n  `ip_dst_addr_geo_city` STRING,\n  `ip_dst_addr_asn_org` STRING,\n  `host_url` STRING,\n  `second_level_domain` STRING,\n  `ip_dst_addr_asn_mask` STRING,\n  `elapsed` STRING,\n  `ip_dst_addr_asn_number` STRING,\n  `ip_src_addr_geo_country` STRING,\n  `ip_dst_addr` STRING,\n  `ip_dst_addr_geo_country` STRING,\n  `ip_dst_addr_geo_lat` STRING,\n  `ip_src_addr_geo_lat` STRING,\n  `message_bytes` STRING,\n  `domain` STRING,\n  `action` STRING,\n  `ip_src_addr` STRING,\n  `dga_model_legit` STRING,\n  `domain_no_subdomains` STRING,\n  `ip_dst_addr_geo_state` STRING,\n  `cyberscore_rule1_id` STRING,\n  `cyberscore_rule1_score` STRING ,\n  `cyberscore_rule1_reason` STRING,\n  `cyberscore_rule2_id` STRING,\n  `cyberscore_rule2_score` STRING ,\n  `cyberscore_rule2_reason` STRING,\n`eventTimestamp` TIMESTAMP(3),\nWATERMARK FOR `eventTimestamp` AS `eventTimestamp` - INTERVAL '10'  SECOND,\nPRIMARY  KEY  (`id`)  NOT ENFORCED\n)  WITH  (\n'connector'  =  'upsert-kafka',\n'topic'  =  'main.network.triage.output.kafka',\n'properties.request.timeout.ms'  =  '3000',\n'properties.bootstrap.servers'  =  'cybersec-cdp-kafka-corebroker2.cybersec.a465-9q4k.cloudera.site:9093,cybersec-cdp-kafka-corebroker1.cybersec.a465-9q4k.cloudera.site:9093, cybersec-cdp-kafka-corebroker0.cybersec.a465-9q4k.cloudera.site:9093',\n'properties.group.id'  =  'triageaggGroup',\n'properties.security.protocol' = 'SASL_SSL',\n--'properties.sasl.mechanism' = 'PLAIN',\n--'properties.sasl.mechanism' = 'KERBEROS',\n'properties.ssl.truststore.location' = '/var/lib/cloudera-scm-agent/agent-cert/cm-auto-global_truststore.jks',\n'properties.auto.offset.reset'  =  'earliest',\n--'format'  =  'json'--,\n'key.format'  =  'json',\n'value.format'  =  'json'\n);\n\nselect * from `main_network_triage_output_kafka`;\n\n\ninsert into `main_network_triage_output_kafka`\nselect `message`.`id` \n, substr(cast(`message`.`ts` as string), 1, 10)  as `ts`\n, `message`.`extensions`['ip_src_addr.geo.longitude'] as ip_src_addr_geo_lon\n, `message`.`extensions`['code'] as code\n, `message`.`extensions`['method'] as `method`\n, `message`.`extensions`['top_level_domain'] as top_level_domain\n, `message`.`extensions`['ip_dst_addr.geo.longitude'] as ip_dst_addr_geo_lon\n, `message`.`extensions`['ip_dst_addr.geo.city'] as ip_dst_addr_geo_city\n, `message`.`extensions`['ip_dst_addr.asn.org'] as ip_dst_addr_asn_org\n, `message`.`extensions`['url'] as host_url\n, `message`.`extensions`['second_level_domain'] as second_level_domain\n, `message`.`extensions`['ip_dst_addr.asn.mask'] as ip_dst_addr_asn_mask\n, `message`.`extensions`['elapsed'] as elapsed\n, `message`.`extensions`['ip_dst_addr.asn.number'] as ip_dst_addr_asn_number\n, `message`.`extensions`['ip_src_addr.geo.country'] as ip_src_addr_geo_country\n, `message`.`extensions`['ip_dst_addr'] as ip_dst_addr\n, `message`.`extensions`['ip_dst_addr.geo.country'] as ip_dst_addr_geo_country\n, `message`.`extensions`['ip_dst_addr.geo.latitude'] as ip_dst_addr_geo_lat\n, `message`.`extensions`['ip_src_addr.geo.latitude'] as ip_src_addr_geo_lat\n, `message`.`extensions`['bytes'] as message_bytes\n, `message`.`extensions`['domain'] as domain\n, `message`.`extensions`['action'] as action\n, `message`.`extensions`['ip_src_addr'] as ip_src_addr\n, `message`.`extensions`['dga_model.legit'] as dga_model_legit\n, `message`.`extensions`['domain_no_subdomains'] as domain_no_subdomains\n, `message`.`extensions`['ip_dst_addr.geo.state'] as ip_dst_addr_geo_state\n, `cyberScoresDetails`[1].`ruleId` as cyberscore_rule1_id\n, cast(`cyberScoresDetails`[1].`score` as VARCHAR) as cyberscore_rule1_score\n, `cyberScoresDetails`[1].`reason` as cyberscore_rule1_reason\n, `cyberScoresDetails`[2].`ruleId` as cyberscore_rule2_id\n, cast(`cyberScoresDetails`[2].`score` as VARCHAR) as cyberscore_rule2_score\n, `cyberScoresDetails`[2].`reason` as cyberscore_rule2_reason\n, TO_TIMESTAMP_LTZ(`message`.`ts`, 3)\nfrom `cybersec-sr`.`default_database`.`main.network.triage.output` \n\n\n/*********************/\nSELECT SUM(CAST(amount AS numeric)) AS payment_volume,\nCAST(TUMBLE_END(eventTimestamp, interval '1' hour) AS varchar) AS ts\nFROM payments\nGROUP BY TUMBLE(eventTimestamp, interval '1' hour);\n\nselect to_timestamp(substr( REGEXP_REPLACE(CAST(TO_TIMESTAMP_LTZ(`message`.`ts`, 3) as STRING), 'T', ' '), 1, 19), 'yyyy-MM-dd HH:mm:ss'), TO_TIMESTAMP_LTZ(`message`.`ts`, 3), substr(CAST(TO_TIMESTAMP_LTZ(`message`.`ts`, 3) as STRING), 1, 10) as ts_date, MINUTE(TO_TIMESTAMP_LTZ(`message`.`ts`, 3)) as ts_hour, `message`, `cyberScoresDetails`, `cyberScore` \nfrom `cybersec-sr`.`default_database`.`main.network.triage.output`\nwhere cyberScore > 50.0\n\n2023-08-01T03:42:07.584Z\n2023-08-01 03:47:32\n2023-08-01T03:52:48\n2023-08-01T03:58:48\n\n\nselect TO_TIMESTAMP_LTZ(`message`.`ts`, 3), substr(CAST(TO_TIMESTAMP_LTZ(`message`.`ts`, 3) as STRING), 1, 10) as ts_date, substr(CAST(TO_TIMESTAMP_LTZ(`message`.`ts`, 3) as STRING), 1, 10) as ts_date\n\nselect  `message`.`extensions`['ip_dst_addr'] as ip_dst_addr, count(1)\nfrom `cybersec-sr`.`default_database`.`main.network.triage.output`\nwhere cyberScore > 50.0\nGROUP BY TUMBLE( FROM_UNIXTIME(FLOOR(`message`.`ts`/ 1000)), interval '1' minute), `message`.`extensions`['ip_dst_addr'] \n\n\n\nselect FROM_UNIXTIME(FLOOR(`message`.`ts`/ 1000)) --CAST(FROM_UNIXTIME(FLOOR(`message`.`ts`/ 1000)) AS TIME)\nfrom `cybersec-sr`.`default_database`.`main.network.triage.output`\nwhere cyberScore > 50.0\n\n\nSELECT window_start, window_end, count(1)\n  FROM TABLE(\n    TUMBLE(TABLE `cybersec-sr`.`default_database`.`main.network.triage.output`, DESCRIPTOR(TO_TIMESTAMP_LTZ(`message`.`ts`, 3)), INTERVAL '10' MINUTES))\n  GROUP BY window_start, window_end;\n\n\nselect * from `ssb`.`ssb_default`.`triage_output_2`\n\nselect message from main_network_triage_output_ktable\n\nselect * from `ssb`.`ssb_default`.`syslog_data_hist` \n\nCREATE TABLE `ssb`.`ssb_default`.`syslog_data_hist` (\n  `priority` INT,\n  `severity` INT,\n  `facility` INT,\n  `version` INT,\n  `syslog_ts` VARCHAR(2147483647),\n  `hostname` VARCHAR(2147483647),\n  `body` VARCHAR(2147483647),\n  `appname` VARCHAR(2147483647),\n  `procid` VARCHAR(2147483647),\n  `messageid` VARCHAR(2147483647),\n  `eventid` VARCHAR(2147483647),\n  `eventsource` VARCHAR(2147483647),\n  `iut` VARCHAR(2147483647)\n) WITH (\n  'catalog-database' = 'cybersec',\n  'catalog-name' = 'cybersec-hive',\n  'hive-conf-dir' = '/etc/hive/conf',\n  'connector' = 'iceberg',\n  'catalog-type' = 'hive'\n)\n\n",
  "mv_config" : {
    "name" : "high_score_aggregate",
    "retention" : 300,
    "min_row_retention_count" : 0,
    "recreate" : false,
    "key_column_name" : null,
    "column_indices_disabled" : false,
    "indexed_columns" : [ ],
    "not_indexed_columns" : [ ],
    "api_key" : null,
    "ignore_nulls" : false,
    "require_restart" : false,
    "batch_size" : 0,
    "enabled" : false
  },
  "runtime_config" : {
    "execution_mode" : "SESSION",
    "parallelism" : 1,
    "sample_interval" : 1000,
    "sample_count" : 100,
    "window_size" : 100,
    "start_with_savepoint" : false,
    "log_config" : {
      "type" : "LOG4J_PROPERTIES",
      "content" : "\nrootLogger.level = INFO\nrootLogger.appenderRef.file.ref = MainAppender\n#Uncomment this if you want to _only_ change Flink's logging\n#logger.flink.name = org.apache.flink\n#logger.flink.level = INFO\n\n# The following lines keep the log level of common libraries/connectors on\n# log level INFO. The root logger does not override this. You have to manually\n# change the log levels here.\nlogger.akka.name = akka\nlogger.akka.level = INFO\nlogger.kafka.name= org.apache.kafka\nlogger.kafka.level = INFO\nlogger.hadoop.name = org.apache.hadoop\nlogger.hadoop.level = INFO\nlogger.zookeeper.name = org.apache.zookeeper\nlogger.zookeeper.level = INFO\n\n# Log all infos in the given file\nappender.main.name = MainAppender\nappender.main.type = File\nappender.main.append = false\nappender.main.fileName = /var/log/ssb\nappender.main.layout.type = PatternLayout\nappender.main.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n\n\n# Suppress the irrelevant (wrong) warnings from the Netty channel handler\nlogger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline\nlogger.netty.level = OFF\n"
    }
  }
}